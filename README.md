# 🧠 LLMGROUND: 실무형 LLM 기반 AI 서비스 개발 스터디 (35주)

> **Python, 수학, 머신러닝/딥러닝 기초부터 RAG, Vector DB, LangChain, Agent, 실전 프로젝트까지!**

---

## 📌 운영 가이드

- **진행 방식**: 주 1회 스터디 + 개인 과제 + 실습 코드 공유  
- **사용 언어/도구**: Python, Jupyter Notebook, LangChain, LlamaIndex, PyTorch, Scikit-learn, OpenAI API, Pinecone, Weaviate 등  
- **공식 언어**: Python  
- **권장 인원**: 3~6명  
- **공유 채널**: GitHub, Discord, Notion  
- **진행 형식**: `이론 학습 → 실습 → 발표 → 코드 리뷰`

---

## 🗂️ 전체 커리큘럼 (35주)

---

### ✅ 1~4주차: Python & 기초 수학

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 1주차 | 파이썬 기초 | 자료형, 함수, 클래스, 예외 처리 |
| 2주차 | 데이터 처리 & IO | 리스트/딕셔너리, 파일 읽기/쓰기, JSON |
| 3주차 | 선형대수 | 벡터, 내적, 행렬곱 |
| 4주차 | 미분 & 확률통계 | 함수 미분, 확률 분포, 평균/분산 |

---

### ✅ 5~8주차: LLM 기본 이해

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 5주차 | Transformer 구조 | Attention, Decoder-only, BERT vs GPT |
| 6주차 | Hugging Face | Transformers 라이브러리 실습 |
| 7주차 | OpenAI API | gpt-3.5-turbo 사용, Completion 실습 |
| 8주차 | Prompt Engineering | Zero/Few-shot, CoT, Role Prompting |

---

### ✅ 9~12주차: RAG & Vector DB 실습

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 9주차 | RAG 개념 | Retriever + Generator 구조 |
| 10주차 | LangChain 기본 | prompt chain, retriever chain 실습 |
| 11주차 | 벡터 DB 실습 | FAISS, Pinecone, cosine similarity |
| 12주차 | LlamaIndex 비교 | LangChain vs LlamaIndex |

---

### ✅ 13~16주차: LangChain 고급 & Agent

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 13주차 | LangChain Memory | BufferMemory, ConversationChain |
| 14주차 | Agent 구조 | ReAct, Zero-shot Agent 실습 |
| 15주차 | Self Query & HyDE | Self-querying, Hypothetical Embedding |
| 16주차 | Hybrid Search | Dense + Sparse, BM25 + Embedding |

---

### ✅ 17~20주차: 실무 서비스 설계

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 17주차 | 멀티턴 대화 시스템 | FAQ 챗봇 설계 및 구현 |
| 18주차 | 외부 API 연동 | Weather/Search API 활용 |
| 19주차 | LangSmith | 트레이싱 및 관찰 도구 |
| 20주차 | LangServe 배포 | FastAPI + LangChain 배포 |

---

### ✅ 21~25주차: 머신러닝/딥러닝 집중 과정

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 21주차 | 머신러닝 기초 | 지도/비지도 학습, 회귀, 분류 |
| 22주차 | 딥러닝 기초 | 퍼셉트론, MLP, 활성화 함수 |
| 23주차 | Transformer 이해 | RNN vs LSTM vs Transformer |
| 24주차 | NLP 응용 | Tokenization, fine-tuning |
| 25주차 | 텍스트 생성 실습 | GPT2 fine-tuning 실습 |

---

### ✅ 26~30주차: 실전 활용 및 최적화

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 26주차 | 문서 요약 & QA | Chunk → 요약 → 질문 응답 |
| 27주차 | 코드 도우미 Agent | 코드 리뷰/설명 챗봇 |
| 28주차 | 멀티모달 & Function Calling | Whisper, DALL·E API 연동 |
| 29주차 | Vector DB 벤치마크 | FAISS vs Pinecone 성능 비교 |
| 30주차 | LangSmith 최적화 | 평가 지표 기반 개선 |

---

### ✅ 31~35주차: 실전 프로젝트 + 배포

| 주차 | 주제 | 학습 내용 |
|------|------|-----------|
| 31~33주차 | 프로젝트 진행 | 예시: FAQ 챗봇, 검색 Agent 등 |
| 34주차 | 배포 최적화 | FastAPI + Docker + Cloud |
| 35주차 | 발표 및 회고 | 기술 블로그 & 포트폴리오 작성 |

---

## 📚 추천 자료

- [The Hundred-Page Machine Learning Book](https://themlbook.com/)
- [Deep Learning with Python - François Chollet](https://www.manning.com/books/deep-learning-with-python)
- [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course)
- [LangChain Cookbook](https://github.com/langchain-ai/langchain-cookbook)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Stanford CS224N](https://web.stanford.edu/class/cs224n/)
- [Whisper GitHub](https://github.com/openai/whisper)

---

## ✅ 활용 팁

- 실습 코드는 `notebooks/` 폴더에 정리  
- 발표자료는 `presentations/` 폴더에 업로드  
- 회고 및 정리는 Notion 또는 `retrospective.md` 작성  
- 팀 블로그/포트폴리오 연계 추천

---

> **LLMGROUND는 실무형 AI 개발자를 위한 스터디입니다. 학습한 내용을 실습으로 연결하고, 실제 서비스 개발까지 이어가는 것이 목표입니다.**

